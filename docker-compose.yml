name: qa-local

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "1024k"
    max-file: "10"

x-services-defaults: &services_defaults
  restart: always
  env_file: .env
  networks:
    - internal
  logging: *default-logging

version: "3.9"

services:
  app:
    <<: *services_defaults
    container_name: qa-app
    build: docker/.
    command: make run
    volumes:
      - ./:/app
    ports:
      - "8080:8080"
    expose:
      - "8080"
    tty: true
    depends_on:
      postgres:
        condition: service_healthy

  postgres:
    <<: *services_defaults
    image: postgres:13.3
    container_name: qa-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres-dev:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    restart: unless-stopped

  migrator:
    <<: *services_defaults
    image: arigaio/atlas:latest-community
    depends_on:
      postgres:
        condition: service_healthy
    container_name: qa-migrator
    command:
      - migrate
      - apply
      - --dir=file://migrations
      - --url=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@qa-postgres:5432/${POSTGRES_DB}?sslmode=disable
    volumes:
      - ./migrations:/migrations:ro
    restart: "no"

  swagger-ui:
    <<: *services_defaults
    image: swaggerapi/swagger-ui
    container_name: qa-swagger-ui
    ports:
      - "8082:8080"
    expose:
      - "8082"
    environment:
      - SWAGGER_JSON=/docs/user_openapi.yaml
      - URLS=[{"url":"/docs/user_openapi.yaml","name":"Client API"}]
    volumes:
      - ./docs:/usr/share/nginx/html/docs

  kafka0:
    <<: *services_defaults
    image: apache/kafka:latest
    hostname: kafka0
    container_name: kafka0
    ports:
      # clients port
      - 9092:9092
      # metrics port
      - 9997:9997
    expose:
      - 9092
      - 9997
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka0:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9997
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9997
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka0:29093"
      KAFKA_LISTENERS: "PLAINTEXT://kafka0:29092,CONTROLLER://kafka0:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_DELETE_TOPIC_ENABLE: "false"

  init-kafka:
    <<: *services_defaults
    image: confluentinc/cp-kafka:6.1.1
    depends_on:
      - kafka0
    restart: 'no'
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka0:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka0:29092 --create --if-not-exists --topic hr.personal --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka0:29092 --create --if-not-exists --topic hr.positions --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka0:29092 --create --if-not-exists --topic hr.history --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka0:29092 --list
      "

  akhq:
    <<: *services_defaults
    image: tchiotludo/akhq:latest
    container_name: qa-akhq
    ports:
      - "8085:8080"
    environment:
      AKHQ_CONFIGURATION: |
        micronaut:
          security:
            enabled: true
            token:
              jwt:
                signatures:
                  secret:
                    generator:
                      secret: "CHANGE_ME_TO_A_LONG_RANDOM_SECRET_32+CHARS"
    
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka0:29092"
    
          security:
            default-group: limited-reader
    
            basic-auth:
              - username: student
                password: "8b1f4ab806281896b34b0528264f90ed0bcfb2610d55974a1e87d355cf962ab0"
                groups:
                  - limited-reader     
                  - hr-producer  
              - username: admin
                password: "8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918"
                groups:
                  - limited-reader     
                  - hr-producer  
    
            roles:
              produce-only:
                - resources: [ "TOPIC_DATA" ]
                  actions:   [ "CREATE" ] 

            groups:
              limited-reader:
                - role: reader
                  # regex: всё, кроме ровно "__consumer_offsets"
                  patterns: [ "^(?!__consumer_offsets$).*" ]
                  clusters: [ "docker-kafka-server" ]
          
              hr-producer:
                - role: produce-only
                  patterns: [ "hr.*" ]
                  clusters: [ "docker-kafka-server" ]
    depends_on:
      - kafka0
    restart: unless-stopped

networks:
  nginx_default:
    external: true
  internal:
    name: qa-${REFNAME:-local}
    driver: bridge

volumes:
  postgres-dev:
  kafka-data:
